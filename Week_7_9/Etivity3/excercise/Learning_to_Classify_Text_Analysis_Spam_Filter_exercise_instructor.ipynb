{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score,confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spam Classification\n",
    "The goal is to predict if an email is spam or not (ham), by using MultinomialNB.\n",
    "\n",
    "The provided dataset has\n",
    "* 5572 rows (number of emails)\n",
    "* 6217 columns \n",
    "\n",
    "The last column is the  class variable (with two values either \"spam\" or \"ham\").\n",
    "The columns 0-6216 represent words (see Header of the  dataset).\n",
    "\n",
    "This is an example of the first 5 rows and first 30 columns of the dataset\n",
    "\n",
    "<img src=\"dtataset_example_email.png\"></img>\n",
    "\n",
    "A zero value means that word is not present in the email (each row is a different email) and a non-zero value\n",
    "is a count and represents the number of times that word is present in that email.\n",
    "The words are stems,  a stem is the form of a word before any inflectional affixes are added.\n",
    "Example: *cost* is a stem for the words, *cost*, *costs*, *costly*.\n",
    "\n",
    "Your task is:\n",
    "1. loading the dataset using pandas\n",
    "2. counting the number of rows and the number of columns\n",
    "3. You don't need datat preprocessing, the input is in the right format for MultinomialNB\n",
    "4. splitting the dataset in inputs (denoted as X, that includes the columns 0-6216) and output (denoted as y, last column)\n",
    "5. randomly splitting the rows in (X,y) in training (50% of the rows) and testing (50% of the rows), you can use the function `train_test_split` from `sklearn`\n",
    "6. training `MultinomialNB` on the training dataset and predict the class variable for the training dataset and testing dataset\n",
    "7. computing the accuracy for the two predictions and also the confusion_matrix for the prediction on the test set.\n",
    "8. implementing your own prediction by thresholding the probability of the class spam and ham,\n",
    "More precisely, if $[p1,p2]$ is the predicted probability for ham and spam for an instance in the test set, the decision is\n",
    "\n",
    "`\n",
    "if p1>threshold\n",
    "    prediction =\"ham\"\n",
    "elif p2>threshold\n",
    "    prediction =\"spam\"\n",
    "else\n",
    "    prediction = \"none\" #this \"none\" means none of the above cases.\n",
    "`    \n",
    "You then need to compute the resulting accuracy for all the cases where the classifier made a decision (that is it returns something different from -1).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Solution\n",
    "\n",
    "## Loading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of rows  5572\n",
      "number of cols  6217\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['ham', 'ham', 'ham', ..., 'ham', 'spam', 'ham'], dtype=object)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#\n",
    "dataset = pd.read_csv(\"email_clean.csv\")\n",
    "print(\"number of rows \", dataset.shape[0])\n",
    "print(\"number of cols \", dataset.shape[1])\n",
    "\n",
    "# splitting input and output\n",
    "X=dataset.iloc[:,0:-1].values\n",
    "y=dataset.iloc[:,-1].values\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split in training and testing\n",
    "x_train, x_test, y_train, y_test=train_test_split(X, y, test_size=0.5, random_state=7)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## training the classifier and making predictions for the training and testing set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MultinomialNB\n",
    "clf=MultinomialNB()\n",
    "#training\n",
    "clf.fit(x_train,y_train)\n",
    "#prediction\n",
    "prediction_train=clf.predict(x_train)\n",
    "prediction_test=clf.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computing accuracy and confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:0.9931801866475233\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#accuracy\n",
    "print(\"Accuracy:\"+str(accuracy_score(y_train,prediction_train)))\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We care about the generalisation error, that is the performance on unseen data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:0.9745154343144293\n",
      "\n",
      "Confusion Matrix\n",
      "[[2352   42]\n",
      " [  29  363]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#accuracy\n",
    "print(\"Accuracy:\"+str(accuracy_score(y_test,prediction_test)))\n",
    "print()\n",
    "#confusion matrix\n",
    "conf_mat=confusion_matrix(y_test, prediction_test)\n",
    "print(\"Confusion Matrix\")\n",
    "print(conf_mat)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.99952141, 0.00047859],\n",
       "       [0.99974511, 0.00025489],\n",
       "       [0.90815815, 0.09184185],\n",
       "       ...,\n",
       "       [0.99990251, 0.00009749],\n",
       "       [0.99967452, 0.00032548],\n",
       "       [0.99999987, 0.00000013]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.set_printoptions(suppress=True)#this suppresses the scientific notation in the visualisation of the porbabilities\n",
    "proba = clf.predict_proba(x_test)\n",
    "proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def new_predict(proba, threshold):\n",
    "    Classes=[\"ham\", \"spam\"]\n",
    "    Output=[]\n",
    "    for i in range(proba.shape[0]):\n",
    "        indmax = np.argmax(proba[i,:])\n",
    "        if proba[i,indmax]>threshold:\n",
    "            Output.append(Classes[indmax])\n",
    "        else:\n",
    "            Output.append(\"none\")\n",
    "    return Output\n",
    "\n",
    "ypred_new = new_predict(proba,0.9999)\n",
    "ind = np.where(np.array(ypred_new)!=\"none\")\n",
    "accuracy_score(np.array(ypred_new)[ind],y_test[ind])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix\n",
      "[[1005 1389    0]\n",
      " [   0    0    0]\n",
      " [   0   90  302]]\n"
     ]
    }
   ],
   "source": [
    "conf_mat=confusion_matrix(y_test, ypred_new)\n",
    "print(\"Confusion Matrix\")\n",
    "print(conf_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
